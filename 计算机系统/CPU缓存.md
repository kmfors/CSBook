# 1. CPU 缓存介绍

CPU 高速缓存集成于 CPU 的内部，其是 CPU 可以高效运行的成分之一，本文围绕下面三个话题来讲解 CPU 缓存的作用：

- 为什么需要高速缓存？
- 高速缓存的内部结构是怎样的？
- 如何利用好 cache，优化代码执行效率？
## 1.1 为什么需要高速缓存？

在现代计算机的体系架构中，为了存储数据，引入了下面一些元件:

1. CPU 寄存器
2. CPU 高速缓存
3. 内存
4. 硬盘

从 1->4，元件工作速度越来越慢，价格越来越低，容量越来越大。这样的设计使得一台计算机的价格会处于一个合理的区间。

由于硬盘的速度比内存访问慢，因此我们在开发应用软件时，经常会使用 redis/memcached 这样的组件来加快速度。

而由于 CPU 和内存速度的不同，于是产生了 CPU 高速缓存。下面这张表反应了 CPU 高速缓存和内存的速度差距：

|  存储器类型   | 时钟周期 |
| :------: | :--: |
| L1 cache |  4   |
| L2 cache |  11  |
| L3 cache |  24  |
|    内存    | 167  |
通常 cpu 内有 3 级缓存，即 L1、L2、L3 缓存。其中 L1 缓存分为数据缓存和指令缓存。

cpu 先从 L1 缓存中获取指令和数据，若 L1 缓存中不存在，则从 L2 缓存中获取。每个 cpu 核心都拥有属于自己的 L1 缓存和 L2 缓存。如果数据不在 L2 缓存中，则从 L3 缓存中获取。而 L3 缓存就是所有 cpu 核心共用的。如果数据也不在 L3 缓存中，则从内存中获取了。当然，如果内存中也没有那就只能从硬盘中获取了。

![[20240914165922.png|600]]


## 1.2 高速缓存的内部结构

CPU Cache 在读取内存数据时，每次不会只读一个字或一个字节，而是一块块地读取，这每一小块数据也叫 CPU 缓存行（CPU Cache Line）。这也是对局部性原理的运用，当一个指令或数据被访问之后，与它相邻地址的数据有很大概率也会被访问，将更多或许被访问 的数据存入缓存，可以进步缓存命中率。

cache line 又分为多种类型，分别为直接映射缓存，多路组相连缓存，全相连缓存。

### 1.2.1 直接映射缓存

直接映射缓存会将一个内存地址固定映射到某一行的 cache line。

其思想是将一个内存地址划分为三块，分别是 Tag, Index，Offset(这里的内存地址指的是虚拟内存)。将 cacheline 理解为一个数组，那么通过 Index 则是数组的下标，通过 Index 就可以获取对应的 cache-line。再获取 cache-line 的数据后，获取其中的 Tag 值，将其与地址中的 Tag 值进行对比，如果相同，则代表该内存地址位于该 cache line 中，即 cache 命中了。最后根据 Offset 的值去 data 数组中获取对应的数据。整个流程大概如下图所示：

![[20240914170836.png|600]]

下面是一个例子，假设 cache 中有 8 个 cache line，

![[20240914171213.png|600]]

对于直接映射缓存而言，其内存和缓存的映射关系如下所示：

![[20240914171254.png|500]]

从图中我们可以看出，0x00，0x40，0x80 这三个地址，其地址中的 index 成分的值是相同的，因此将会被加载进同一个 cache line。

试想一下如果我们依次访问了 0x00，0x40，0x00 会发生什么？

当我们访问 0x00 时，cache miss，于是从内存中加载到第 0 行 cache line 中。当访问 0x40 时，第 0 行 cache line 中的 tag 与地址中的 tag 成分不一致，因此又需要再次从内存中加载数据到第 0 行 cache line 中。最后再次访问 0x00 时，由于 cache line 中存放的是 0x40 地址的数据，因此 cache 再次 miss。可以看出在这个过程中，cache 并没有起什么作用，访问了相同的内存地址时，cache line 并没有对应的内容，而都是从内存中进行加载。

这种现象叫做 cache 颠簸（cache thrashing）。针对这个问题，引入多路组相连缓存。下面一节将讲解多路组相连缓存的工作原理。


# 参考资料

- [CPU 缓存那些事](https://codebuilding.blog.csdn.net/article/details/132086242)